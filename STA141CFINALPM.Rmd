---
title: "STA141C Final Project"
author: "Your Name"
date: "2024-05-25"
output: html_document
---

# Introduction

The goal is to predict the severity of obesity problems using various machine learning techniques.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load Libraries
library(tidyverse)
library(dplyr)
library(readr)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(glmnet)
library(pROC)
library(ggplot2)
library(corrplot)
library(car)
library(e1071) 
library(reshape)
library(broom)
```



```{r load-data}
# Read the data
data <- read.csv("US Project Data.csv")

# Ensure that the data frame is a tibble for better compatibility with tidyverse functions
data <- as_tibble(data)

# Select the needed columns explicitly using dplyr::select to avoid conflicts
data <- data %>%
  dplyr::select(MedianIncE, P_HS, P_FastFood, P_Doctor, Obesity_Prob)

# View the first few rows of the modified data
print(head(data))


df_summary = data %>%
  group_by(Obesity_Prob) %>%
  summarise(count = n(),
            proportion = n() / nrow(data))
df_summary


#this is a 49:51 ratio, which is relatively balanced. 

# Recode as numeric
data = data %>%
  mutate(
    ObesityProb_numeric = case_when(
      Obesity_Prob == "Higher Severity" ~ 1,
      Obesity_Prob == "Lower Severity" ~ 0
    )
  )
# Standardize the predictor variables
data <- data %>%
  mutate(across(c(MedianIncE, P_HS, P_FastFood, P_Doctor), scale))

```


```{r}
#split the dataset into testing and training 
# Calculate the mean of the numeric response variable


# Split the data into training (60%) and testing (40%) sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(data$ObesityProb_numeric, p = 0.6, list = FALSE)

trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

# Create X_train, X_test, Y_train, Y_test
X_train <- trainData %>% dplyr::select(MedianIncE, P_HS, P_FastFood, P_Doctor)
Y_train <- trainData$ObesityProb_numeric

X_test <- testData %>% dplyr::select(MedianIncE, P_HS, P_FastFood, P_Doctor)
Y_test <- testData$ObesityProb_numeric

# Print the sizes of the training and testing sets
print(paste("Training set size:", nrow(trainData)))
print(paste("Testing set size:", nrow(testData)))

# Create summary tables for class distribution
train_summary <- trainData %>%
  group_by(ObesityProb_numeric) %>%
  summarise(count = n(), proportion = n() / nrow(trainData))

test_summary <- testData %>%
  group_by(ObesityProb_numeric) %>%
  summarise(count = n(), proportion = n() / nrow(testData))

# Print the summary tables
print("Training set class distribution:")
print(train_summary)

print("Testing set class distribution:")
print(test_summary)

```


```{r}
# Fit the logistic regression model with all predictors and their interactions
model <- glm(Y_train ~ (MedianIncE + P_HS + P_FastFood + P_Doctor)^2, 
             data = cbind(X_train, Y_train), 
             family = binomial())

# Summary of the model
summary(model)

```


```{r}
# Perform stepwise selection to find the best model
#best_model <- step(initial_model, direction = "both")

# Summary of the best model
#summary(best_model)
```

```{r}
# Generate predictions on the testing data using the model
testData$logistic_predictions <- predict(model, newdata = X_test, type = "response")

# Evaluate the model performance on the testing set
# Convert predictions to binary outcomes using a threshold of 0.5
testData$predicted_class <- ifelse(testData$logistic_predictions > 0.5, 1, 0)

# Create a confusion matrix
confusion_matrix <- table(Predicted = testData$predicted_class, Actual = Y_test)

# Print the confusion matrix
print(confusion_matrix)
```

```{r}
# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy: ", accuracy))

# Calculate feature importance
importance <- broom::tidy(model) %>%
  mutate(importance = abs(estimate)) %>%
  arrange(desc(importance))

# Print feature importance
print(importance)

# Plot feature importance
importance %>%
  ggplot(aes(x = reorder(term, importance), y = importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Feature Importance", x = "Features", y = "Importance") +
  theme_minimal()
```

```{r}
# Fit the classification tree with tuning parameters
tree_model <- rpart(Y_train ~ MedianIncE + P_HS + P_FastFood + P_Doctor, 
                    data = cbind(X_train, Y_train), method = "class",
                    control = rpart.control(minsplit = 20, cp = 0.01))

# Print and plot the tree model with rpart.plot for better visualization
print(tree_model)
rpart.plot(tree_model)

# Generate predictions on the testing data using the tree model
testData$tree_predictions <- predict(tree_model, newdata = X_test, type = "class")

# Create a confusion matrix for the classification tree
confusion_matrix_tree <- table(Predicted = testData$tree_predictions, Actual = Y_test)

# Print the confusion matrix for the classification tree
print(confusion_matrix_tree)

# Calculate accuracy for the classification tree
accuracy_tree <- sum(diag(confusion_matrix_tree)) / sum(confusion_matrix_tree)
print(paste("Classification Tree Accuracy: ", accuracy_tree))
```

```{r}
# Fit the random forest model
set.seed(123)
rf_model <- randomForest(Y_train ~ MedianIncE + P_HS + P_FastFood + P_Doctor, 
                         data = cbind(X_train, Y_train), ntree = 500, mtry = 2, importance = TRUE)

# Print the random forest model
print(rf_model)

# Generate predictions on the testing data using the random forest model
testData$rf_predictions <- predict(rf_model, newdata = X_test)

# Create a confusion matrix for the random forest
confusion_matrix_rf <- table(Predicted = testData$rf_predictions, Actual = Y_test)

# Print the confusion matrix for the random forest
print(confusion_matrix_rf)

# Calculate accuracy for the random forest
accuracy_rf <- sum(diag(confusion_matrix_rf)) / sum(confusion_matrix_rf)
print(paste("Random Forest Accuracy: ", accuracy_rf))

# Plot variable importance
importance_rf <- importance(rf_model)
varImpPlot(rf_model)
```

